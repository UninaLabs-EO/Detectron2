{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rotated_ships_example",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.2 64-bit ('coast': conda)"
    },
    "accelerator": "GPU",
    "interpreter": {
      "hash": "0e69631618c4709356f6b0774f511e8035aaeb2e548ebf52fb8b07a9bd62ac62"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxM1KQZO_6rv"
      },
      "source": [
        "# Detectron2 (FAIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq_wI0iYNZWq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deb6c087-bed7-4ec8-ef66-3ab35c7c103e"
      },
      "source": [
        "import detectron2\n",
        "import contextlib\n",
        "import datetime\n",
        "import io\n",
        "import os\n",
        "import json\n",
        "import logging\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import copy,torch,torchvision\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import xml.etree.ElementTree as X\n",
        "import math\n",
        "from itertools import repeat\n",
        "\n",
        "from detectron2.structures import Boxes, BoxMode, PolygonMasks\n",
        "from detectron2.config import *\n",
        "from detectron2.modeling import build_model\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.data import transforms as T\n",
        "from detectron2.data import detection_utils as utils\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
        "from detectron2.checkpoint import DetectionCheckpointer\n",
        "from detectron2.evaluation import COCOEvaluator,DatasetEvaluators, inference_on_dataset, coco_evaluation, DatasetEvaluator\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "from detectron2.utils.logger import setup_logger\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import glob\n",
        "import time\n",
        "import shutil\n",
        "from multiprocessing.pool import ThreadPool\n",
        "import concurrent.futures\n",
        "\n",
        "from utility.LossEvalHook import LossEvalHook\n",
        "from utility.mytrainer import MyTrainer\n",
        "from utility.nms import non_max_suppression_fast\n",
        "\n",
        "import torch\n",
        "torch.cuda.set_device(0)\n",
        "\n",
        "setup_logger()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aWxnKl8pJz0"
      },
      "source": [
        "## Dataset preperation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "register_coco_instances(\"ship_dataset_train\", {}, \"ShipAnnotations/train2017.json\", \"ShipDataset\")\n",
        "register_coco_instances(\"ship_dataset_val\", {}, \"ShipAnnotations/test2017.json\", \"ShipDataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "register_coco_instances(\"wake_dataset_train\", {}, \"Sar Wakes 3/train/coco.json\", \"Sar Wakes 3/train/imgs\")\n",
        "register_coco_instances(\"wake_dataset_val\", {}, \"Sar Wakes 3/validation/coco.json\", \"Sar Wakes 3/validation/imgs\")\n",
        "# MetadataCatalog.get(\"wake_dataset_train\").set(thing_classes=[\"wake\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I0LCzBCNeJd"
      },
      "source": [
        "## Setup configuration\n",
        "Now we've got out data in a usable form,and some useful functions lets configure our tests. below are the options for training, "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7unkuuiqLdqd"
      },
      "source": [
        "cfg = get_cfg()\n",
        "cfg.OUTPUT_DIR = 'output'\n",
        "#  Let training initialize from models.txt\n",
        "MODEL = \"Misc/cascade_mask_rcnn_R_50_FPN_3x.yaml\"\n",
        "cfg.merge_from_file(model_zoo.get_config_file(MODEL))\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(MODEL) #\n",
        "cfg.DATASETS.TRAIN = (\"wake_dataset_train\",)\n",
        "cfg.DATASETS.TEST = (\"wake_dataset_val\",)\n",
        "\n",
        "# cfg.MODEL.MASK_ON=False\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8 \n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # this is far lower than usual.  \n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES =  1             # only has one class.\n",
        "cfg.MODEL.RETINANET.NUM_CLASSES =  1\n",
        "\n",
        "cfg.SOLVER.IMS_PER_BATCH = 1          \n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = 500\n",
        "cfg.TEST.EVAL_PERIOD = 500\n",
        "cfg.SOLVER.BASE_LR = 0.005\n",
        "cfg.SOLVER.GAMMA = 0.5\n",
        "cfg.SOLVER.STEPS=[1000,1200,2500,3000]\n",
        "cfg.SOLVER.MAX_ITER=5000\n",
        "\n",
        "cfg.MODEL.PIXEL_MEAN = [70, 70, 70]\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "# cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = True \n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)#lets just check our output dir exists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KUDANtq53M0"
      },
      "source": [
        "## Training\n",
        "### Load tensorboard to view progress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnpIJJXFKt_S"
      },
      "source": [
        "# # Look at training curves in tensorboard:\n",
        "# %reload_ext tensorboard\n",
        "# %tensorboard --logdir \"output\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOpi4T9DoYYV"
      },
      "source": [
        "### Start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gysMa97r57i"
      },
      "source": [
        "# # cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "# trainer = MyTrainer(cfg) \n",
        "# trainer.resume_or_load(resume=True)\n",
        "# trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9pSlGrxUyWl"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "The results produced about aren't as accurate as those performed outside of training. So let's rerun our evaluations. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R-Z_CWp1tqH",
        "outputId": "1872979c-39ce-445e-8b19-d55c2f522640"
      },
      "source": [
        "# # Create coco evaluator, but use the default detectron2 data format for generation, make sure ids overlap\n",
        "# evaluator = COCOEvaluator(\"wake_dataset_val\", cfg, False, output_dir=cfg.OUTPUT_DIR)\n",
        "# val_loader = build_detection_test_loader(cfg, \"wake_dataset_val\") \n",
        "# outputs = inference_on_dataset(trainer.model, val_loader, evaluator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9ffPLVUaXVS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "outputId": "ad0cc330-0d2a-450c-9349-20270602905d"
      },
      "source": [
        "cfg.MODEL.WEIGHTS = \"checkpoints/Model Trained Wake/cascade_mask_rcnn_R_50_FPN_3x/model_0002979.pth\"\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8 \n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utility.myVisualizer import MyVisualizer\n",
        "# test_dict = get_dataset(\"wake_dataset_val\")\n",
        "test_img = glob.glob('Sar Wakes 3/validation/imgs/*.png')\n",
        "for d in random.sample(test_img, 10):\n",
        "  im = cv2.imread(d)\n",
        "  outputs = predictor(im)  \n",
        "  v = MyVisualizer(im[:, :, ::-1],\n",
        "                  metadata=MetadataCatalog.get(\"wake_dataset_val\"), \n",
        "                  scale=1)\n",
        "\n",
        " \n",
        "  out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.imshow(out.get_image()[:, :, ::-1])\n",
        "  plt.axis(False)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from utility.printProgressBar import printProgressBar\n",
        "\n",
        "# im = cv2.imread('ScenariTest/ShipWakeTerraSAR-X/VV.tiff')\n",
        "# y,x = im.shape[0], im.shape[1] \n",
        "# step, ws = 500, 650\n",
        "# range_x, range_y = np.arange(ws, x-ws, step), np.arange(ws, y-ws, step)\n",
        "# print(f\"Number of subsets to be analyzed: {len(range_x)*len(range_y)}\")\n",
        "# Bboxes = []\n",
        "# i=0\n",
        "# for space_x in range_x:\n",
        "#     for space_y in range_y:\n",
        "#         printProgressBar(i, len(range_x)*len(range_y), printEnd=' ')\n",
        "#         i+=1\n",
        "#         img = im[(space_y-ws):(space_y+ws),(space_x-ws):(space_x+ws)]\n",
        "#         outputs = predictor(img)\n",
        "#         bboxes=outputs[\"instances\"].pred_boxes.tensor.cpu().numpy()\n",
        "#         for b in bboxes: \n",
        "#             # Each row is (x1, y1, x2, y2).\n",
        "#             b[0], b[1], b[2], b[3] = b[0]+space_x, b[1]+space_y, b[2]+space_x, b[3]+space_y\n",
        "#             Bboxes.append(b)\n",
        "\n",
        "# Bboxes_arr = np.array(Bboxes) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# bboxes_draw = non_max_suppression_fast(Bboxes_arr, 0.33)\n",
        "# for box in bboxes_draw:\n",
        "#     # represents the top left corner of rectangle\n",
        "#     start_point =  (box[0], box[1])\n",
        "#     # represents the bottom right corner of rectangle\n",
        "#     end_point = (box[2], box[3])\n",
        "#     color = (255, 0, 0)\n",
        "#     linethickness = 3\n",
        "#     image = cv2.rectangle(im, start_point-ws, end_point-ws, color, linethickness)\n",
        "# cv2.imwrite('ImageTest.png', image) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# im = cv2.imread('ScenariTest/ShipWakeTerraSAR-X/VV.tiff')\n",
        "# test = im[7000+4000:9000+4000,6100:8100]\n",
        "# outputs = predictor(test)  \n",
        "# v = Visualizer(test[:, :, ::-1],\n",
        "#                   metadata=MetadataCatalog.get(\"wake_dataset_val\"), \n",
        "#                   scale=1)\n",
        "#                   # instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
        "#   # )\n",
        "# out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "# plt.figure(figsize=(10,10))\n",
        "# plt.imshow(out.get_image()[:, :, ::-1])\n",
        "# plt.axis(False)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# im = cv2.imread('ScenariTest/ShipWakeTerraSAR-X/VV.tiff')\n",
        "# test = im[7000+4000:9000+4000,6100:8100]\n",
        "# outputs = predictor(test)  \n",
        "\n",
        "# bboxes=outputs[\"instances\"].pred_boxes.tensor.cpu().numpy()\n",
        "# for box in bboxes:\n",
        "#     start_point =  (box[0], box[1])\n",
        "#         # represents the bottom right corner of rectangle\n",
        "#     end_point = (box[2], box[3])\n",
        "#     color = (255, 0, 0)\n",
        "#     linethickness = 5\n",
        "#     image = cv2.rectangle(test, start_point, end_point, color, linethickness)\n",
        "# cv2.imwrite('ImageTest.png', image) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bboxes"
      ]
    }
  ]
}